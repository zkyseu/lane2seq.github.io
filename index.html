<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>simpleHand</title>
<link href="./front_files/style.css" rel="stylesheet">
<script type="text/javascript" src="./front_files/jquery.mlens-1.0.min.js"></script> 
<script type="text/javascript" src="./front_files/jquery.js"></script>


<style>
  p.serif{
    font-family:"Times New Roman", Times, serif;
  }
  p.sansserif{
    font-family: Arial, Helvetica, sans-serif;
  }
</style>
  
</head>

<body>
<div class="content">
  <p style="text-align: center;"> <h1><strong> Lane2Seq: Towards Unified Lane Detection via<br> Sequence Generation</strong><small>(CVPR 2024)</small></h1></p>
  <p id="authors" class="serif">

    Kunyang Zhou
    <br>
    <span style="font-size: 0.8em; margin-top: 0.5em">
      Southeast University
      <br>
      kunyangzhou@seu.edu.cn
    <!-- </sup>JIIOV Technology
      <a href="https://en.jiiov.com/"></sup>JIIOV Technology</a> -->
    </span>
  </p>

  <font size="+1">
    <p style="text-align: center;" class="serif">
      <a href="https://arxiv.org/pdf/2402.17172.pdf" target="_blank" style="font-weight: bold;">[Paper]</a>&nbsp;&nbsp;&nbsp;&nbsp;
      <a href="https://github.com/zkyseu/PPlanedet" target="_blank" style="font-weight: bold;">[Github(Coming soon)]</a>&nbsp;&nbsp;&nbsp;&nbsp;
      <a href="#bibtex" style="font-weight: bold;">[BibTeX]</a>
    </p><br>
  </font>

<!DOCTYPE html>
<html>
<head>
    <!-- <title>YouTube Video Embed</title> -->
    <style>
        .video-container {
            text-align: center; /* 使内部元素居中 */
        }
        .video-container iframe {
            margin: 0 auto; /* iframe自身居中 */
            display: block; /* 防止出现额外的空间 */
        }
    </style>
</head>

<body>
    <!-- YouTube Video -->
    <!-- <div class="content">
      <img class="summary-img" src="figs/fig1.png" style="width:100%;"> <br> -->

    <div class="video-container">
      <img class="summary-img" src="figs/fig1.png" style="width:50%;">
        <!-- <iframe width="640" height="360" src="https://www.youtube.com/embed/4mlu0kzl-OY" frameborder="0" allowfullscreen></iframe> -->
    </div>

</body>
</html>
  
  <!-- <p style="text-align:left; font-size: 2em; font-weight: bold" class="serif"></p> -->
    <!-- <p style="text-align: center; font-size: 1.2em" class="serif">Click to play the demo video. An alternate Bilibili source is <a href="https://www.bilibili.com/video/BV1Jx42127bZ/" target="_blank" style="font-weight: bold;">HERE</a>.</p> -->
    <p style="text-align: left; font-size: 1.2em" class="serif">
      In this paper, we present a novel sequence generation-based framework for lane detection, called Lane2Seq. It unifies various lane detection formats by casting lane detection as a sequence generation task. 
      This is different from previous lane detection methods, which depend on well-designed task-specific head networks and corresponding loss functions. Lane2Seq only adopts a plain transformer-based encoder-decoder architecture with a simple cross-entropy loss. 
      Additionally, we propose a new multi-format model tuning based on reinforcement learning to incorporate the task-specific knowledge into Lane2Seq. Experimental results demonstrate that such a simple sequence generation paradigm not only unifies lane detection but also achieves competitive performance on benchmarks. 
      For example, Lane2Seq gets 97.95% and 97.42% F1 score on Tusimple and LLAMAS datasets, establishing a new state-of-the-art result for two benchmarks.
    </p>

</div>

<div class="content">
  <p style="text-align:left; font-size: 2em; font-weight: bold" class="serif">Methodology</p>
  <p style="font-size: 1.2em" class="serif">
    In this paper, we present a novel sequence generation-based lane detecton (Lane2Seq) framework to tackle the aforementioned issues. By formulating the lane detection as a sequence generation task, Lane2Seq gets rid of customized head networks and task-specific loss function. 
    It is based on the intuition that if the detection model knows where the target lane is, model can be simply teached how to read the location of lane out, instead of designing additional classification head or regression head by the divide-and-conquer strategy. <br>
    While Lane2Seq does not contain task-specific components, task-specific knowledge contained in these components can help the model learn the features of lanes better. We propose a Multi-Format model tuning method based on Reinforcement Learning (MFRL) to incorporate the task-specific knowledge into the model without changing model's architecture. Inspired by Task-Reward, MFRL takes the evaluation metrics,
    which naturally integrates task-specific knowledge, as the reward and tunes Lane2Seq using REINFORCE algorithm. However, evaluation metrics like F1 score cannot be used as the reward directly due to undecomposable as a sum of per-example rewards. In this paper, we propose three new evaluation metric-based rewards for segmentation, anchor, and parameter format, based on their task-specific knowledge.<br>
  </p>
  <img class="summary-img" src="figs/fig2.png" style="width:100%;"> <br>
</div>

<div class="content">
  <p style="text-align:left; font-size: 2em; font-weight: bold" class="serif">Results and Comparisons</p>
  <p style="font-size: 1.2em" class="serif">
    <img class="summary-img" src="figs/result1.png" style="width:90%;"> <br>
    <img class="summary-img" src="figs/result2.png" style="width:70%;"> <br>
    <img class="summary-img" src="figs/result3.png" style="width:70%;"> <br>
    Based on the above results, we can conclude that the unified lane detection via the sequence generation without any well-designed task-specific components, combining our reinforcement learning-based multi-format model tuning, can achieve promising performance.
  </p>
</div>

<div class="content">
  <p style="text-align:left; font-size: 2em; font-weight: bold" class="serif">About me</p>
  <p style="font-size: 1.2em" class="serif">
    I am a second-year (2022-now) M.S. student in School of Automation, Southeast University.<br>
    <p style="font-size: 1.2em; font-weight: bold" class="serif">Open source contribution</p>
    <p style="font-size: 1.2em" class="serif">I've been working to open source meaningful projects for the PaddlePaddle community. So far, I've gotten 5.5K forks in the PaddlePaddle community and am a top 100 contributing developer! 
    My homepage in the PaddlePaddle community is <a href="https://aistudio.baidu.com/personalcenter/thirdview/297029">here</a>.
    <br> </p>
    <!-- <p style="font-size: 1.2em; font-weight: bold" class="serif">Our mission</p><p style="font-size: 1.2em" class="serif"> Creating a brand new interactive experience with AI and sensors, enable the world to accelerate into a fully intelligent era.</p>
    <p style="font-size: 1.2em; font-weight: bold" class="serif">Our vision</p><p style="font-size: 1.2em" class="serif"> Creating an era of safe, user-friendly, convenient and smart interaction.</p>
    <p style="font-size: 1.2em; font-weight: bold" class="serif">Through the ongoing efforts of all JIIOV employees, we confidently provide you with better, smarter products and experiences.<br>
    — Chen Keqing </p> -->
  </p>
</div>
</div>

<div class="content" id="bibtex">
  <p style="text-align:left; font-size: 2em; font-weight: bold" class="serif">BibTeX</p>
  <code> @misc{zhou2024lane2seq,<br>
  &nbsp;&nbsp;title={Lane2Seq: Towards Unified Lane Detection via Sequence Generation},<br>
  &nbsp;&nbsp;author={Kunyang Zhou},<br>
  &nbsp;&nbsp;booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},<br>
  &nbsp;&nbsp;year={2024},<br>
  } </code> 
</div>

<head>
  <meta charset="UTF-8">
  <title>中文楷体字体示例</title>
  <style>
      .chinese-kaiti {
          /* font-family: '楷体', '楷体_GB2312', 'Kaiti', '仿宋', serif; */
          font-family: 'MyKaiti';
      }
  </style>
  </head>

<div class="content">
  <p style="text-align:left; font-size: 2em; font-weight: bold" class="serif">Acknowledgment</p>
  <p style="font-size: 1.2em" class="serif">
    I would like to express my sincere thank to my girlfriend very much for her support and encouragement throughout this project. Her companionship gave me the strength I needed to complete this project.
  </p>
</div>

<div class="content">
  <p class="serif">
    Project page template is borrowed from <a href="https://simplehand.github.io/">simplehand</a>.
  </p>
</div>

</body>

<script>
var videos = document.getElementsByClassName("clickplay");
for (var i = 0; i < videos.length; i++) {
  videos[i].addEventListener("click", function() {
    this.play();
  });
  videos[i].addEventListener("ended", function() {
    this.pause();
    this.currentTime = 0;
  });
}
</script>

</html>
